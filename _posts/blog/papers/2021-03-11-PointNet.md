---
layout: post
bigtitle:  "PointNet"
subtitle:   ": Deep Learning on Point Sets for 3D Classification and Segmentation"
categories:
    - blog
    - papers
tags:
    - point-cloud
    - detection
comments: true
published: true
---




# PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation

Charles R. Qi Hao Su Kaichun Mo Leonidas J. GuibasStanford University

## Abstract

Point cloud is an important type of geometric data structure.  
Due to its irregular format, most researchers transform such data to regular 3D voxel grids or collections of images.  
This, however, renders data unnecessarily voluminous and causes issues.  

> Point cloud는 기하학 데이터 구조의 중요한 type이다.
불규칙한 포맷으로 인해 대부분의 연구자들은 이러한 데이터를 일반 3D voxel grids 또는 collections of images 로 변환한다.
그러나 이로 인해 데이터가 불필요하게 대량으로 생성되고 문제가 발생합니다.

In this paper, we design a novel type of neural network that directly consumes point clouds, which well respects the permutation invariance of points in the input.  

> 본 논문에서, 우리는 point cloud를 직접 소비하는 새로운 유형의 neural network을 설계하는데, 이는 입력에서 points의 순열 불변성을 잘 respect한다.

Our network, named PointNet, provides a unified architecture for applications ranging from object classification, part segmentation, to scene semantic parsing.  
Though simple, PointNet is highly efficient and effective.  
Empirically, it shows strong performance on par or even better than state of the art.  
Theoretically, we provide analysis towards understanding of what the network has learnt and why the network is robust with respect to input perturbation and corruption.

> PointNet이라는 이름의 우리의 네트워크는 object classification, part segmentation,scene semantic parsing에 이르는 애플리케이션을 위한 통합 아키텍처를 제공한다.
PointNet은 간단하지만 매우 효율적이고 효과적입니다.
경험적으로, 그것은 최신것보다 동등하거나 훨씬 더 나은 성능을 보여준다.
이론적으로, 우리는 네트워크가 학습한 내용과 input perturbation 및 corruption과 관련하여 네트워크가 robust한 이유를 이해하기 위한 분석을 제공한다.

## 1 Introduction

In this paper we explore deep learning architectures capable of reasoning about 3D geometric data such as point clouds or meshes.  
Typical convolutional architectures require highly regular input data formats, like those of image grids or 3D voxels, in order to perform weight sharing and other kernel optimizations.

> 본 논문에서는 point clouds나 meshes와 같은 3D geometric data에 대해 추론할 수 있는 deep learning architectures를 탐구한다.  
일반적인 convolutional architectures는 weight sharing 및 other kernel optimizations를 수행하기 위해 image grids 또는 3D voxels과 같은 매우 규칙적인 입력 데이터 형식이 필요하다.

Since point clouds or meshes are not in a regular format, most researchers typically transform such data to regular 3D voxel grids or collections of images (e.g, views) before feeding them to a deep net architecture.  
This data representation transformation, however, renders the resulting data unnecessarily voluminous — while also introducing quantization artifacts that can obscure natural invariances of the data.

> point clouds 또는 meshes는 정규 형식이 아니기 때문에, 대부분의 연구자들은 일반적으로 이러한 데이터를 deep net 아키텍처에 공급하기 전에 regular 3D voxel grids 또는 collections of images(예: views)로 변환한다.  
그러나 이러한 데이터 표현 변환은 resulting data를 불필요하게 풍부하게 만드는 동시에 natural invariances of the data을 모호하게 할 수 있는 quantization artifacts를 도입한다.

For this reason we focus on a different input representation for 3D geometry using simply point clouds and name our resulting deep nets PointNets.  
Point clouds are simple and unified structures that avoid the combinatorial irregularities and complexities of meshes, and thus are easier to learn from.  
The PointNet, however, still has to respect the fact that a point cloud is just a set of points and therefore invariant to permutations of its members, necessitating certain symmetrizations in the net computation.  
Further invariances to rigid motions also need to be considered.

> 이러한 이유로 우리는 단순히 point clouds를 사용하여 3D geometry에 대한 다른 입력 표현에 초점을 맞추고 우리의 결과인 deep nets의 이름을 PointNets로 지정한다.  
Point clouds는 meshes의 combinatorial irregularities와 복잡성을 피하는 단순하고 통합된 구조이므로 쉽게 배울 수 있다.  
그러나 PointNet은 point cloud가 단지 a set of points 이므로 point cloud의 각 point의 permutations에는 불변한다는 사실을 존중해야 하며, net 계산에서 특정 symmetrizations(대칭화)가 필요하다.
경직된 동작에 대한 추가 불변성도 고려할 필요가 있다.

Our PointNet is a unified architecture that directly takes point clouds as input and outputs either class labels for the entire input or per point segment/part labels for each point of the input.    
The basic architecture of our network is surprisingly simple as in the initial stages each point is processed identically and independently.    
In the basic setting each point is represented by just its three coordinates (x, y, z).  
Additional dimensions may be added by computing normals and other local or global features.

> 우리의 PointNet은 point cloud를 입력으로 직접 가져와서 전체 입력에 대한 class labels 또는 입력의 각 point에 대한 point segment/part labels을 출력하는 unified architecture이다.  
우리 network의 기본 architecture는 초기 단계에서 각 point가 동일하고 독립적으로 처리되기 때문에 놀라울 정도로 간단하다.  
기본 설정에서 각 point은 세 개의 좌표(x, y, z)로만 표시됩니다.
표준 및 기타 local 또는 global features을 계산하여 추가 차원을 추가할 수 있다.

Key to our approach is the use of a single symmetric function, max pooling.  
Effectively the network learns a set of optimization functions/criteria that select interesting or informative points of the point cloud and encode the reason for their selection.  
The final fully connected layers of the network aggregate these learnt optimal values into the global descriptor for the entire shape as mentioned above (shape classification) or are used to predict per point labels (shape segmentation).

> 우리의 접근 방식의 핵심은 single symmetric function인 max pooling의 사용이다.  
network는 point cloud의 interesting한 또는 informative한 points를 선택하고 선택 이유를 인코딩하는 a set of optimization functions/criteria을 효과적으로 학습한다.
network의 final fully connected layers는 위에서 언급한 entire shape에 대해 학습된 최적 값(optimal values)을  global descriptor로 집계하거나(shape classification) point labels을 예측하는 데 사용된다.(shape segmentation)

Our input format is easy to apply rigid or affine transformations to, as each point transforms independently.  
Thus we can add a data-dependent spatial transformer network that attempts to canonicalize the data before the PointNet processes them, so as to further improve the results.

> 우리의 input format은 각 point가 독립적으로 변환될 때 rigid or affine 변환을 적용하기가 쉽다.  
따라서 우리는 PointNet이 data를 처리하기 전에 data를 canonicalize를 시도하는 data-dependent spatial transformer network를 추가하여 결과를 더욱 개선할 수 있다.

We provide both a theoretical analysis and an experimental evaluation of our approach.  
We show that our network can approximate any set function that is continuous.  
More interestingly, it turns out that our network learns to summarize an input point cloud by a sparse set of key points, which roughly corresponds to the skeleton of objects according to visualization.  
The theoretical analysis provides an understanding why our PointNet is highly robust to small perturbation of input points as well as to corruption through point insertion (outliers) or deletion(missing data).

> 우리는 우리의 접근 방식에 대한 이론적 분석과 실험 평가를 제공한다.  
우리는 우리의 네트워크가 연속적인 모든 설정 함수에 근사할 수 있다는 것을 보여준다.
더 흥미롭게도, 우리 네트워크는 visualization에 따라 대략 skeleton of objects에 해당하는 희박한 set of key points으로 입력 point cloud를 요약하는 방법을 학습하는 것으로 밝혀졌다.  
이론적 분석은 우리의 PointNet이 왜 small perturbation of input points 뿐만 아니라 point 삽입(outliers) 또는 삭제(missing data)를 통한 손상에도 매우 robust한지 이해할 수 있게 해준다.

On a number of benchmark datasets ranging from shape classification, part segmentation to scene segmentation, we experimentally compare our PointNet with state-of-the-art approaches based upon multi-view and volumetric representations.  
Under a unified architecture, not only is our PointNet much faster in speed, but it also exhibits strong
performance on par or even better than state of the art.

> shape classification, part segmentation에서 scene segmentation에 이르는 많은 benchmark datasets에서, 우리는 multi-view 및 volumetric representations을 기반으로 하는 최신 접근 방식과 우리의 PointNet을 실험적으로 비교한다.
unified architecture에서는 PointNet의 속도가 훨씬 빠를 뿐만 아니라 강력한 성능을 제공합니다.

The key contributions of our work are as follows: (이 네트워크의 주요 기여)

- We design a novel deep net architecture suitable for consuming unordered point sets in 3D(LiDAR로 수집한 데이터);
- We show how such a net can be trained to perform 3D shape classification, shape part segmentation and
scene semantic parsing tasks;
- We provide thorough empirical and theoretical analysis on the stability and efficiency of our method;
- We illustrate the 3D features computed by the selected neurons in the net and develop intuitive explanations for its performance.
